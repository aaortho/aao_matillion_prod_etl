type: "orchestration"
version: "1.0"
pipeline:
  components:
    Start:
      type: "start"
      transitions:
        unconditional:
        - "get last run date time"
      parameters:
        componentName: "Start"
    get last run date time:
      type: "query-to-scalar"
      transitions:
        success:
        - "Orders incremental"
      parameters:
        componentName: "get last run date time"
        mode: "Advanced"
        query: "SELECT \r\n    TABLE_NAME, \r\n    TO_CHAR(MAX(LOAD_TIME), 'YYYY-MM-DD\"\
          T\"HH24:MI:SS\"Z\"') AS LAST_LOAD_TIME\r\nFROM \r\n    PROD_BRONZE_DB.LMS.LMS_AUDIT_LOG\r\
          \nWHERE \r\n    TABLE_NAME = 'ORDERS CREATED'\r\n    AND LOAD_STATUS = 'SUCCESS'\r\
          \nGROUP BY \r\n    TABLE_NAME\r\nORDER BY \r\n    LAST_LOAD_TIME DESC"
        scalarVariableMapping:
        - - "v_created_after"
          - "LAST_LOAD_TIME"
      postProcessing:
        updateOutputMessage:
        updateScalarVariables:
    Orders incremental:
      type: "modular-api-extract-input-v2"
      transitions:
        success:
        - "Log Orders Ingestion"
        failure:
        - "Log Orders API Failure"
      parameters:
        componentName: "Orders incremental"
        componentId: "custom_v2-01ba2d07-e6ae-413d-a524-b9f50f046c72"
        inputId: "api-extract-input-v2"
        api-extract-input-v2:
          profile: "custom-01ba2d07-e6ae-413d-a524-b9f50f046c72"
          endpoint: "Orders incremental"
          connectionRef:
            overrides:
              authType: "NONE"
          uriParams:
          queryParams:
          - name: "created_after"
            value: "${v_created_after}"
          headerParams:
          postBody:
          pageLimit:
          logLevel: "ERROR"
          loadSelectedData: "No"
        outputId: "snowflake-output-connector-v0"
        snowflake-output-connector-v0:
          warehouse: "[Environment Default]"
          database: "[Environment Default]"
          schema: "LMS"
          tableName: "ORDERS"
          createTableMode: "TRUNCATE_AND_INSERT"
          cleanStagedFiles: "Yes"
          stagePlatform: "SNOWFLAKE"
          snowflake#internalStageType: "USER"
      postProcessing:
        updateOutputMessage:
        updateScalarVariables:
    Log Orders API Failure:
      type: "sql-executor"
      parameters:
        componentName: "Log Orders API Failure"
        scriptLocation: "Component"
        declareSqlVariables: "Include selected"
        variablesToInclude:
        sqlScript: |
          -- Log failure to audit table with error details
          INSERT INTO PROD_BRONZE_DB.LMS.LMS_AUDIT_LOG (
              TABLE_NAME,
              ROW_COUNT,
              LOAD_TIME,
              LOAD_STATUS,
              ERROR_MESSAGE
          )
          VALUES (
              'ORDERS CREATED',
              -1,  -- Negative count indicates failure
              CURRENT_TIMESTAMP,
              'FAILED',  -- Load status indicating failure
              'Failed: Unknown error occurred during LMS Orders API processing'
          );
      postProcessing:
        updateOutputMessage:
        updateScalarVariables:
    Log Orders Ingestion:
      type: "sql-executor"
      transitions:
        success:
        - "Data Parser Orders"
      parameters:
        componentName: "Log Orders Ingestion"
        scriptLocation: "Component"
        declareSqlVariables: "Include all"
        sqlScript: "-- Log success to audit table\nINSERT INTO PROD_BRONZE_DB.LMS.LMS_AUDIT_LOG\
          \ (\n    TABLE_NAME,\n    ROW_COUNT,\n    LOAD_TIME,\n    LOAD_STATUS,\n\
          \    ERROR_MESSAGE\n)\nSELECT \n    'ORDERS CREATED' AS TABLE_NAME,\n  \
          \  COUNT(*) AS ROW_COUNT,\n    CURRENT_TIMESTAMP AS LOAD_TIME,\n    'SUCCESS'\
          \ AS LOAD_STATUS,\n    NULL AS ERROR_MESSAGE\nFROM PROD_BRONZE_DB.LMS.ORDERS;\n"
    Data Parser Orders:
      type: "sql-executor"
      transitions:
        success:
        - "Run pl_lms_order_details_incremental_load"
      parameters:
        componentName: "Data Parser Orders"
        scriptLocation: "Component"
        declareSqlVariables: "Include selected"
        variablesToInclude:
        sqlScript: "MERGE INTO PROD_SILVER_DB.LMS.ORDERS AS target\r\nUSING (\r\n\
          \    SELECT\r\n        item.value:uuid::STRING AS uuid,\r\n        item.value:created_at::TIMESTAMP\
          \ AS created_at,\r\n        item.value:external_reference::STRING AS external_reference,\r\
          \n        item.value:status::STRING AS status,\r\n\r\n        item.value:user.id::STRING\
          \ AS user_id,\r\n        item.value:user.api_username::STRING AS api_username,\r\
          \n        item.value:user.email::STRING AS user_email,\r\n        item.value:user.first_name::STRING\
          \ AS first_name,\r\n        item.value:user.last_name::STRING AS last_name,\r\
          \n\r\n        (item.value:current_totals.total::NUMBER)/100 AS current_total\r\
          \n    FROM PROD_BRONZE_DB.LMS.ORDERS,\r\n         LATERAL FLATTEN(input\
          \ => DATA_VALUE:data) AS item\r\n) AS source\r\nON target.uuid = source.uuid\r\
          \n\r\nWHEN MATCHED THEN\r\n    UPDATE SET\r\n        target.created_at =\
          \ source.created_at,\r\n        target.external_reference = source.external_reference,\r\
          \n        target.status = source.status,\r\n        target.user_id = source.user_id,\r\
          \n        target.api_username = source.api_username,\r\n        target.user_email\
          \ = source.user_email,\r\n        target.first_name = source.first_name,\r\
          \n        target.last_name = source.last_name,\r\n        target.current_total\
          \ = source.current_total\r\n\r\nWHEN NOT MATCHED THEN\r\n    INSERT (\r\n\
          \        uuid,\r\n        created_at,\r\n        external_reference,\r\n\
          \        status,\r\n        user_id,\r\n        api_username,\r\n      \
          \  user_email,\r\n        first_name,\r\n        last_name,\r\n        current_total\r\
          \n    )\r\n    VALUES (\r\n        source.uuid,\r\n        source.created_at,\r\
          \n        source.external_reference,\r\n        source.status,\r\n     \
          \   source.user_id,\r\n        source.api_username,\r\n        source.user_email,\r\
          \n        source.first_name,\r\n        source.last_name,\r\n        source.current_total\r\
          \n    );\r\n"
      postProcessing:
        updateOutputMessage:
        updateScalarVariables:
    Run pl_lms_order_details_incremental_load:
      type: "run-orchestration"
      parameters:
        componentName: "Run pl_lms_order_details_incremental_load"
        orchestrationJob: "lms_data_ingestion/LMS Incremental Data Ingestion/pl_lms_order_details_incremental_load.orch.yaml"
        setScalarVariables:
        setGridVariables:
      postProcessing:
        updateOutputMessage:
        updateScalarVariables:
  variables:
    v_created_after:
      metadata:
        type: "TEXT"
        description: ""
        scope: "COPIED"
        visibility: "PUBLIC"
      defaultValue: "2019-01-01T00:00:00Z"
design:
  components:
    Start:
      position:
        x: -220
        "y": -30
      tempMetlId: 1
    get last run date time:
      position:
        x: -110
        "y": -30
      tempMetlId: 3
    Orders incremental:
      position:
        x: 40
        "y": -30
      tempMetlId: 4
    Log Orders API Failure:
      position:
        x: 240
        "y": -140
      tempMetlId: 10
    Log Orders Ingestion:
      position:
        x: 200
        "y": -30
      tempMetlId: 11
    Data Parser Orders:
      position:
        x: 350
        "y": -30
      tempMetlId: 12
    Run pl_lms_order_details_incremental_load:
      position:
        x: 490
        "y": -30
      tempMetlId: 13
